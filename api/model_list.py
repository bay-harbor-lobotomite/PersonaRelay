models = [
"meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
"deepseek-ai/DeepSeek-R1-0528",
"Qwen/Qwen3-235B-A22B-FP8",
"meta-llama/Llama-3.3-70B-Instruct",
"google/gemma-3-27b-it",
"mistralai/Magistral-Small-2506",
"mistralai/Devstral-Small-2505",
"deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
"deepseek-ai/DeepSeek-R1",
"deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
"microsoft/phi-4",
"nvidia/AceMath-7B-Instruct",
"mistralai/Mistral-Large-Instruct-2411",
"bespokelabs/Bespoke-Stratos-32B",
"netease-youdao/Confucius-o1-14B",
"CohereForAI/aya-expanse-32b",
"THUDM/glm-4-9b-chat",
"mistralai/Ministral-8B-Instruct-2410",
"openbmb/MiniCPM3-4B",
"ibm-granite/granite-3.1-8b-instruct",
"Qwen/Qwen2.5-VL-32B-Instruct",
"meta-llama/Llama-3.2-90B-Vision-Instruct",
"BAAI/bge-multilingual-gemma2",
]